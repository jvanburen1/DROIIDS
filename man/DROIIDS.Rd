% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/DROIIDS.R
\name{DROIIDS}
\alias{DROIIDS}
\title{Dimension Reduction On Independent Infectious Disease Systems}
\usage{
DROIIDS(analysis.name = NULL, z = NA, x = NULL, Phi = NULL,
  n.Phi.vectors = NA, Phi.method = "FA", n.cores = 3, n.chains = 3,
  seed = NA, burnin.iters = 1000, autocorr.thin.level = 0.5,
  thinning.value = NULL, impute = FALSE, n.iter.chain = 200,
  converge.check = TRUE, num.iter.loops = 5)
}
\arguments{
\item{analysis.name}{A character string giving the name of the analysis.}

\item{z}{The set of outcome data containing ID, time, and observations. See details below for exact setup of \code{z}.}

\item{x}{An optional matrix of baseline predictor variables.}

\item{Phi}{A dimension reduction matrix created from the data.}

\item{n.Phi.vectors}{The number of vectors in the dimension reduction matrix to be created if Phi is not provided.}

\item{Phi.method}{The method to create Phi if Phi is not provided.  Options include factor analysis (\code{FA})
or empirical orthogonal functions (\code{EOF}).  The default method is factor analysis.}

\item{n.cores}{The number of computer cores to be used during the analysis.}

\item{n.chains}{The number of chains to be used in analysis.}

\item{seed}{The specified seed for generating random numbers.}

\item{burnin.iters}{The number of iterations to burn-in before determining the autocorrelation thinning value.}

\item{autocorr.thin.level}{The minimum acceptable autocorrelation between the location variances, latent variances,
and coefficient parameters when determining a thinning value.}

\item{thinning.value}{Specifies the thinning value to use. This will overwrite the autocorrelation procedure.}

\item{impute}{Indicator (\code{TRUE/FALSE}) of whether missing data in \code{z} should be imputed.}

\item{n.iter.chain}{The total number of iterations output per chain after thinning.}

\item{converge.check}{An indicator of whether the Gelman and Rubin univariate convergence tests should be used to
test for convergence between chains during the analysis.}

\item{num.iter.loops}{The number of iteration cycles that should be performed before forced termination.}
}
\value{
A list containing information of the DROIIDS analysis is produced from this function.  Information in this list is used to create summary statistics,
   calculate predicted estimates and rates of changes, and plot the data.
}
\description{
This function uses a Bayesian hierarchical model to analyze and pool inferences on a set of data
   containing correlated observations collected across time on independent subjects. This model provides predicted estimates on
   the data accounting for variability in the measurements. The data and process models are:

   Data Model: \eqn{z_{i,t}=\Phi a_{i,t} + 1_L X_{i} \beta + \epsilon_{i,t}}

   Process Model: \eqn{a_{i,t} = a_{i,t-1} + \eta_{i,t}}

   where \eqn{z_{i,t}} is a vector of \code{L} normally distributed correlated outcome variables for individual \code{i} at
   time \code{t}. \eqn{\Phi} is a dimension reduction matrix created from the data and \eqn{a_{i,t}} is a vector of latent
   variables corresponding to the dimension reduction matrix.  \eqn{X_{i}} and \eqn{\beta} are baseline covariate data
   and corresponding population parameters, respectively.  Location errors and latent errors are represented by
   \eqn{\epsilon_{i,t}} and \eqn{\eta_{i,t}}, respectively.
}
\details{
The \code{analysis.name} is the character string that will be used in all outfile names.

   Each independent spatio-temporal dataset is stacked to form one overall data frame (\code{z}).  This structure needs to
   either be a "matrix" or "data.frame".  Any missed visit in \code{z} needs to be accounted for with indicators of missing
   values (\code{NA}).  All ID numbers should be represented the same number of times in \code{z}. The structure for the
   outcome data frame is as follows:
   \itemize{
     \item The first column ("\code{ID}") contains the numeric ID numbers of all subjects.
     \item The second column ("\code{time}") contains the specific time points for all subjects.
     \item The third through remaining columns of \code{z} contain the location observations.
   }

   \code{x} is an optional data frame or matrix containing baseline covariates for each individual.  The first column
   should be the individual's ID number ("\code{ID}") and correspond to the same order of IDs as the observed data (\code{z}). By default,
   the DROIIDS function sets covariate usage to \code{NULL} allowing for usage of the DROIIDS model without covariates.

   \code{Phi} is a dimension reduction matrix (a data frame or a matrix). This matrix should be created to account for variability
   in the data. Each row in Phi, \eqn{\Phi}\code{_l},  contains the multiplicative values for location \code{l} that will be combined with
   the latent variable estimates.  This matrix should have dimension (\code{L x p}) where \code{p} is both the number of dimension reduction matrix vectors
   and the number of latent variables estimated per person at each time point.  If the user does not provide a dimension reduction matrix,
   the DROIIDS function will create one using the specified number of vectors (\code{n.Phi.vectors}) and the creation method (\code{Phi.method}).
   By default, a factor analysis (\code{FA}) with a Varimax rotation on the first \code{n.Phi.vectors} empirical orthogonal functions is
   used to create Phi.  Empirical Orthogonal Functions (\code{EOF}) is a second option that can be used to create Phi.  The maximum number of
   vectors allowed is half of the number of locations in the analysis. Researchers recommend using no more than 0.1*L vectors in the creation
   of Phi where L is the number of locations.

   The vector of location errors (\eqn{\epsilon_{i,t} = (\epsilon_{i,t,1}, ..., \epsilon_{i,t,l}, ..., \epsilon_{i,t,L})}) are assumed to be
   drawn from independent distributions.  Location error \eqn{\epsilon_{i,t,l}} for individual \code{i}, at time \code{t} and location \code{l}
   are assumed to be drawn from a normal distribution with variance \eqn{\sigma^2_{\epsilon,l}}. That is, \eqn{\epsilon_{i,t,l} ~ N(0,\sigma^2_{\epsilon,l})}
   for all \code{i} and \code{t}. Similarly, the vector of latent variances (\eqn{\eta_{i,t} = (\eta_{i,t,1}, ..., \eta_{i,t,k}, ..., \eta_{i,t,p})}) are
   assumed to be drawn from independent distributions.  The error \eqn{\eta_{i,t,k}} for the \code{k}th vector among the \code{n.Phi.vectors}
   latent variables is assumed to follow a normal distribution with variance \eqn{\sigma^2_{\eta,k}}. That is, \eqn{\eta_{i,t,k} ~ N(0,\sigma^2_{\eta,k})}
   for all \code{i} and \code{t}.

   \code{n.cores} is the number of computer cores that will be used when finding the posterior distribution on the current machine.
   This option allows for parallel computing when working with multiple chains.  The default number of cores used is 3.

   \code{n.chains} is the number of chains in the analysis used to estimate the posterior distributions. The default
   number of chains is 3.

   \code{seed} specifies the random number generator.  If no seed is specified, one will be randomly chosen and saved in the output.

   \code{burnin.iters} specifies how many iterations to burn prior to determining the thinning level.

   After the specified burn-in, 1000 iterations are output and the autocorrelations within and between the location variances, latent variances,
   and covariates (if included) are calculated for every lag up to 100 on these 1000 iterations.  The maximum acceptable autocorrelation
   between the location variances (\eqn{\sigma^2_\epsilon}), latent variances (\eqn{\sigma^2_\eta}), and covariates (\eqn{\beta}) (if included) when determining the thinning value can be specified with
   \code{autocorr.thin.level}.  The lag that has every autocorrelation less than pre-specified acceptance level (\code{autocorr.thin.level})
   is chosen. The next increment of 5 from the chosen lag is used as the thinning value. For example, if the lag that has every autocorrelation
   less than \code{autocorr.thin.level} is 13, then 15 would be used as the thinning value.

   After completion of the first set of \code{n.iter.chain} iterations after the burn-in, the iterations from each chain are imported and convergence is assessed using the Gelman and Rubin
   convergence diagnostic (potential scale reduction factor â€“ PSRF) for all location variances, latent variances, and covariate parameters if \code{converge.check = TRUE}.  If at least one parameter in this group
   did not converge, the iteration process outputting a new set of \code{n.iter.chain} iterations is repeated using the last observed iteration values of the parameters as
   starting values. This iterative cycle continues until there is convergence between the chains or until it looped through a maximum of \code{num.iter.loops}
   times, whichever happens first. Convergence tests are not performed if the DROIIDS function is imputing data.

   \code{impute} is an indicator (\code{TRUE}/\code{FALSE}) of whether imputation should be performed on missing data.  If there are
   missing data and impute = \code{FALSE}, only individuals with a complete set of data will remain in the analysis.  If \code{impute = TRUE}, the
   missing data are substituted using the mean of the quadratic fit for that individuals location over time.  After the burn-in and autocorrelation sections, the last observed
   latent variables and covariate parameter estimates are used to impute missing data using the data model. These imputed values are then fixed
   until a new iteration cycle occurs.

   Vague, conjugate priors are used in the posterior estimation process. The following priors are used by the \code{DROIIDS} function:
   \itemize{
     \item Latent variable \eqn{k, k=1,..p} for individual \eqn{i} at time 0: (\eqn{a_{i,k,t=0} ~ N(0,(\sqrt{1000})^2)}
     \item Covariate \eqn{b, b=1,..,B}: \eqn{\beta_b ~ N(0,(\sqrt{1000})^2)}
     \item Location variance \eqn{l, l=1,...,L}: \eqn{\sigma^2_\epsilon ~ InverseGamma(0.001, 0.001)}
     \item Latent variable variance \eqn{k, k=1,...,p}: \eqn{\sigma^2_\eta ~ InverseGamma(0.001, 0.001)}
     \item Missing data \eqn{z_{i,t,l}} for individual \eqn{i}, time point \eqn{t}, and location \eqn{l}: \eqn{z_{i,t,l} ~ N(0,(\sqrt{1000})^2)}
   }
}

